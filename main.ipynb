{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d95a6a3",
   "metadata": {},
   "source": [
    "## Importando Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a19d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas gerais\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Modelos categóricos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Modelos regressores\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e42c333",
   "metadata": {},
   "source": [
    "## Extraindo dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32ee3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = \"wine_quality.csv\"\n",
    "target_column = \"type\"\n",
    "\n",
    "df = pd.read_csv(\"data/\"+csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a05b1e7",
   "metadata": {},
   "source": [
    "## Primeira visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6aadd8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality type  \n",
       "0      9.4        5  red  \n",
       "1      9.8        5  red  \n",
       "2      9.8        5  red  \n",
       "3      9.8        6  red  \n",
       "4      9.4        5  red  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa54990",
   "metadata": {},
   "source": [
    "## Tratando colunas não numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acc269eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabrielbento-ieg\\AppData\\Local\\Temp\\ipykernel_14040\\1715094219.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='raise')\n"
     ]
    }
   ],
   "source": [
    "for col, dtype in df.dtypes.items():\n",
    "    if dtype == object:\n",
    "        try:\n",
    "            # Tentativa de conversão para datetime\n",
    "            df[col] = pd.to_datetime(df[col], errors='raise')\n",
    "\n",
    "            df[col+\"_month_sin\"] = np.sin(2*np.pi*df[col].dt.month/12)\n",
    "            df[col+\"_month_cos\"] = np.cos(2*np.pi*df[col].dt.month/12)\n",
    "            df[col+\"_day_sin\"]   = np.sin(2*np.pi*df[col].dt.day/31)\n",
    "            df[col+\"_day_cos\"]   = np.cos(2*np.pi*df[col].dt.day/31)\n",
    "\n",
    "            df = df.drop(col, axis=1)\n",
    "        except Exception:\n",
    "            n_categories = df[col].nunique()\n",
    "            if n_categories <= 10 and col != target_column:\n",
    "                ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "                encoded = ohe.fit_transform(df[[col]])\n",
    "\n",
    "                # Cria nomes de colunas legíveis\n",
    "                encoded_cols = [f\"{col}_{cat}\" for cat in ohe.categories_[0]]\n",
    "\n",
    "                # Concatena com o DataFrame original\n",
    "                df = pd.concat([df.drop(columns=[col]), pd.DataFrame(encoded, columns=encoded_cols, index=df.index)], axis=1)\n",
    "            elif col != target_column:\n",
    "                le = LabelEncoder()\n",
    "                df[col] = le.fit_transform(df[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32829c57",
   "metadata": {},
   "source": [
    "## Separação teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49447388",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(target_column, axis=1)\n",
    "y = df[target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,        # porcentagem para teste\n",
    "    random_state=42,      # garante reprodutibilidade\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a55a8a",
   "metadata": {},
   "source": [
    "## Setando os modelos a serem treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40a1995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(y.dtype)\n",
    "if y.dtype == object or y.dtype == bool:\n",
    "    \n",
    "    result = DecisionTreeClassifier().cost_complexity_pruning_path(X_train, y_train)\n",
    "    ccp_alphas = result.ccp_alphas\n",
    "    ccp_alphas = np.delete(ccp_alphas, -1)\n",
    "    \n",
    "    scoring = 'accuracy'\n",
    "    \n",
    "    models = {\n",
    "        \"Decision Tree Gini\": DecisionTreeClassifier(criterion='gini', random_state=42),\n",
    "        \"Decision Tree Entropy\": DecisionTreeClassifier(criterion='entropy', random_state=42),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"KNN\": KNeighborsClassifier(),\n",
    "        \"BernoulliNB\": BernoulliNB(),\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        \"Decision Tree Gini\": {\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_leaf': [1, 5, 10],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'splitter': ['best', 'random'],\n",
    "            'ccp_alpha': ccp_alphas,\n",
    "            'class_weight': [None, 'balanced']\n",
    "        },\n",
    "        \"Decision Tree Entropy\": {\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_leaf': [1, 5, 10],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'splitter': ['best', 'random'],\n",
    "            'ccp_alpha': ccp_alphas,\n",
    "            'class_weight': [None, 'balanced']\n",
    "        },\n",
    "        \"Naive Bayes\": {\n",
    "                'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "            },\n",
    "        \"KNN\": {\n",
    "            'n_neighbors': [3, 5, 7, 9],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['euclidean', 'manhattan', 'minkowski', 'cosine'],\n",
    "        },\n",
    "        \"BernoulliNB\": {\n",
    "            'alpha': [0.5, 1.0, 1.5],\n",
    "            'binarize': [0.0, 0.5, 1.0],\n",
    "            'fit_prior': [True, False]\n",
    "        },\n",
    "    }\n",
    "else:\n",
    "    \n",
    "    scoring = 'r2'\n",
    "    \n",
    "    models = {\n",
    "        \"Linear Regressor\": LinearRegression(),\n",
    "        \"KNN Regressor\": KNeighborsRegressor(),\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        \"Linear Regressor\": {\n",
    "        \"fit_intercept\": [True, False],\n",
    "        \"copy_X\": [True],\n",
    "        \"positive\": [False, True],\n",
    "    },\n",
    "    \"KNN Regressor\": {\n",
    "        \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"p\": [1, 2],  # 1 = Manhattan, 2 = Euclidiana\n",
    "        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\"],\n",
    "    },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b22cd",
   "metadata": {},
   "source": [
    "## Treinando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0457d08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando e ajustando Decision Tree Gini...\n",
      "Fitting 5 folds for each of 6624 candidates, totalling 33120 fits\n",
      "Melhores parâmetros para Decision Tree Gini: {'ccp_alpha': 0.00012809227729298028, 'class_weight': 'balanced', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Melhor accuracy de validação: 0.9861\n",
      "Treinando e ajustando Decision Tree Entropy...\n",
      "Fitting 5 folds for each of 6624 candidates, totalling 33120 fits\n",
      "Melhores parâmetros para Decision Tree Entropy: {'ccp_alpha': 0.00037299625523600866, 'class_weight': None, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "Melhor accuracy de validação: 0.9867\n",
      "Treinando e ajustando Naive Bayes...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Melhores parâmetros para Naive Bayes: {'var_smoothing': 1e-09}\n",
      "Melhor accuracy de validação: 0.9715\n",
      "Treinando e ajustando KNN...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Melhores parâmetros para KNN: {'metric': 'cosine', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "Melhor accuracy de validação: 0.9671\n",
      "Treinando e ajustando BernoulliNB...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Melhores parâmetros para BernoulliNB: {'alpha': 0.5, 'binarize': 0.5, 'fit_prior': True}\n",
      "Melhor accuracy de validação: 0.8559\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Treinando e ajustando {name}...\")\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[name],\n",
    "        cv=5,  # validação cruzada com 5 folds\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,  # usa todos os núcleos do processador\n",
    "        verbose=1\n",
    "    )\n",
    "    grid.fit(X_train, y_train)  # treino\n",
    "\n",
    "    print(f\"Melhores parâmetros para {name}: {grid.best_params_}\")\n",
    "    print(f\"Melhor {scoring} de validação: {grid.best_score_:.4f}\")\n",
    "\n",
    "    best_models[name] = grid.best_estimator_    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9440427",
   "metadata": {},
   "source": [
    "## Mostrando as métricas de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54954937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decision Tree Gini ===\n",
      "Acurácia no teste: 0.9846\n",
      "Matriz de confusão:\n",
      "[[330  11]\n",
      " [  9 950]]\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.97      0.97      0.97       341\n",
      "       white       0.99      0.99      0.99       959\n",
      "\n",
      "    accuracy                           0.98      1300\n",
      "   macro avg       0.98      0.98      0.98      1300\n",
      "weighted avg       0.98      0.98      0.98      1300\n",
      "\n",
      "\n",
      "=== Decision Tree Entropy ===\n",
      "Acurácia no teste: 0.9754\n",
      "Matriz de confusão:\n",
      "[[324  17]\n",
      " [ 15 944]]\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.96      0.95      0.95       341\n",
      "       white       0.98      0.98      0.98       959\n",
      "\n",
      "    accuracy                           0.98      1300\n",
      "   macro avg       0.97      0.97      0.97      1300\n",
      "weighted avg       0.98      0.98      0.98      1300\n",
      "\n",
      "\n",
      "=== Naive Bayes ===\n",
      "Acurácia no teste: 0.9685\n",
      "Matriz de confusão:\n",
      "[[330  11]\n",
      " [ 30 929]]\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.92      0.97      0.94       341\n",
      "       white       0.99      0.97      0.98       959\n",
      "\n",
      "    accuracy                           0.97      1300\n",
      "   macro avg       0.95      0.97      0.96      1300\n",
      "weighted avg       0.97      0.97      0.97      1300\n",
      "\n",
      "\n",
      "=== KNN ===\n",
      "Acurácia no teste: 0.9669\n",
      "Matriz de confusão:\n",
      "[[316  25]\n",
      " [ 18 941]]\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.95      0.93      0.94       341\n",
      "       white       0.97      0.98      0.98       959\n",
      "\n",
      "    accuracy                           0.97      1300\n",
      "   macro avg       0.96      0.95      0.96      1300\n",
      "weighted avg       0.97      0.97      0.97      1300\n",
      "\n",
      "\n",
      "=== BernoulliNB ===\n",
      "Acurácia no teste: 0.8515\n",
      "Matriz de confusão:\n",
      "[[161 180]\n",
      " [ 13 946]]\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.93      0.47      0.63       341\n",
      "       white       0.84      0.99      0.91       959\n",
      "\n",
      "    accuracy                           0.85      1300\n",
      "   macro avg       0.88      0.73      0.77      1300\n",
      "weighted avg       0.86      0.85      0.83      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    if scoring == 'accuracy':\n",
    "        print(f\"Acurácia no teste: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(\"Matriz de confusão:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"Relatório de classificação:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    else:\n",
    "        print(f\"R² no teste: {r2_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"MAE (Erro Absoluto Médio): {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "        print(f\"MSE (Erro Quadrático Médio): {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "        print(f\"RMSE (Raiz do Erro Quadrático Médio): {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "        print(\"Resumo estatístico:\")\n",
    "        print(f\"Valor real médio: {np.mean(y_test):.4f}\")\n",
    "        print(f\"Valor previsto médio: {np.mean(y_pred):.4f}\")\n",
    "        print(f\"Desvio padrão das previsões: {np.std(y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ada1f",
   "metadata": {},
   "source": [
    "## Definindo melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9ea5c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhor modelo geral: Decision Tree Gini\n"
     ]
    }
   ],
   "source": [
    "if scoring == 'accuracy':\n",
    "    best_model_name = max(best_models, key=lambda n: accuracy_score(y_test, best_models[n].predict(X_test)))\n",
    "else:\n",
    "    best_model_name = max(best_models, key=lambda n: r2_score(y_test, best_models[n].predict(X_test)))\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(f\"\\nMelhor modelo geral: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcbcab",
   "metadata": {},
   "source": [
    "## Salvando o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d4909bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "with open(f\"models/best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
